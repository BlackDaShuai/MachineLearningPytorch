{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-06T12:15:00.395351Z",
     "start_time": "2024-10-06T12:15:00.375351Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms,datasets\n",
    "from torch import nn,optim\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.cuda.is_available())  # 应该返回True\n",
    "print(torch.cuda.device_count())  # 返回可用的GPU数量\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "# torch.cuda.amp\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T12:15:00.521363Z",
     "start_time": "2024-10-06T12:15:00.473612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 载入训练集数据，同时把数据转换为tensor，同时下载数据\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# 载入测试集数据，同时把数据转换为tensor，同时下载数据\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "# 文件分别为训练集测试集他们分别的数据和标签"
   ],
   "id": "e361a23405836e96",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T12:15:07.350123Z",
     "start_time": "2024-10-06T12:15:00.539362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 批次大小\n",
    "batch_size = 64\n",
    "# 装载数据集,dataloader为数据的装载器，数据来源于dataset=train_dataset, 大小为batch_size=batch_size，方式为随机打乱\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=8)\n",
    "# 展示数据\n",
    "for i,data in enumerate(train_loader):\n",
    "    inputs, labels = data\n",
    "    print(inputs.shape)\n",
    "    print(labels.shape)\n",
    "    break"
   ],
   "id": "63de0bba86aac892",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1, 28, 28])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T12:15:07.427459Z",
     "start_time": "2024-10-06T12:15:07.414156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Dop = 0.1 # 0.1的神经元不工作\n",
    "class Net(nn.Module):\n",
    "    # 初始化，定义网络结构\n",
    "    def __init__(self):\n",
    "        # 初始化nnModule\n",
    "        super(Net, self).__init__()\n",
    "        # 定义了一个全连接层，参数为输入值和输出值个数\n",
    "        # 由于是非线性回归，一层神经网络无法做到，因此需要加入隐藏层\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 32, 5,1,2),nn.ReLU(),nn.MaxPool2d(2,2))\n",
    "        # 输入通道数（黑白1彩色3）、输出通道数（生成32个特征图）、卷积核大小、步长、padding=2，即padding两圈0\n",
    "        # 加入Relu激活函数，使其非线性\n",
    "        # 池化为2*2，步长为2\n",
    "        self.conv2 = nn.Sequential(nn.Conv2d(32, 64, 5,1,2),nn.ReLU(),nn.MaxPool2d(2,2))\n",
    "        # 64个特征图，大小为7*7（28*28卷积后变成28*28，池化后变成14*14，再次卷积后池化变成7*7）\n",
    "        self.fc1 = nn.Sequential(nn.Linear(64*7*7,500),nn.Dropout( p = Dop),nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(500,100),nn.Dropout( p = Dop),nn.ReLU())\n",
    "        self.fc3 = nn.Sequential(nn.Linear(100,10),nn.Softmax(dim=1))\n",
    "        \n",
    "    # 前向计算，定义网络计算\n",
    "    def forward(self, x):\n",
    "        # ([64, 1, 28, 28])\n",
    "        # 卷积要求四维数据，格式如上\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # ([64, 64, 7, 7])\n",
    "        # 4维变2维\n",
    "        x = x.view(x.size()[0],-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        outs = self.fc3(x)\n",
    "        return outs"
   ],
   "id": "ed3ae497980d3470",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T12:15:07.490720Z",
     "start_time": "2024-10-06T12:15:07.460529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LR = 0.001\n",
    "# 定义模型\n",
    "model = Net()\n",
    "model.to(device)\n",
    "# 定义损失函数,交叉熵损失\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "# 优化器，设置L2正则化\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR ,weight_decay=0.0001)"
   ],
   "id": "94c6a9fed0bada0f",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T12:15:07.536861Z",
     "start_time": "2024-10-06T12:15:07.522862Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    # 训练状态\n",
    "    model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        # 获得一个批次的数据和标签\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        out = model(inputs)\n",
    "        # 交叉熵无需使用独热编码\n",
    "        loss = cross_entropy(out, labels)\n",
    "        # 梯度清零，计算梯度，修改权值\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test():\n",
    "    # 测试状态\n",
    "    model.eval()\n",
    "    # 计算测试集的准确率\n",
    "    correct = 0\n",
    "    for i, data in enumerate(test_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        out = model(inputs)\n",
    "        # 计算out中，最大值所在位置\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        \n",
    "        correct += (predicted == labels).sum()\n",
    "    print(\"Test acc:{0}\".format(correct.item() / len(test_loader.dataset)))\n",
    "    \n",
    "    \n",
    "    # 计算训练集的准确率\n",
    "    correct = 0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        out = model(inputs)\n",
    "        # 计算out中，最大值所在位置\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        \n",
    "        correct += (predicted == labels).sum()\n",
    "    print(\"Train acc:{0}\".format(correct.item() / len(train_loader.dataset)))\n",
    "        "
   ],
   "id": "ee8a602f45963fd1",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-06T12:15:07.569466Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(20):\n",
    "    \n",
    "    train()\n",
    "    print('epoch:', epoch,' train over')\n",
    "    \n",
    "    test()\n",
    "    \n",
    "    if LR >= 0.00001:\n",
    "        LR = LR * 0.3\n",
    "    \n",
    "    \n",
    "# 一共1w张测试集"
   ],
   "id": "80e173109b3dff31",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  train over\n",
      "Test acc:0.8485\n",
      "Train acc:0.8428666666666667\n",
      "epoch: 1  train over\n",
      "Test acc:0.9611\n",
      "Train acc:0.9601\n",
      "epoch: 2  train over\n",
      "Test acc:0.9785\n",
      "Train acc:0.9754833333333334\n",
      "epoch: 3  train over\n",
      "Test acc:0.9828\n",
      "Train acc:0.9819\n",
      "epoch: 4  train over\n",
      "Test acc:0.9839\n",
      "Train acc:0.9831166666666666\n",
      "epoch: 5  train over\n",
      "Test acc:0.9837\n",
      "Train acc:0.9832666666666666\n",
      "epoch: 6  train over\n",
      "Test acc:0.9845\n",
      "Train acc:0.9868166666666667\n",
      "epoch: 7  train over\n",
      "Test acc:0.9887\n",
      "Train acc:0.98895\n",
      "epoch: 8  train over\n",
      "Test acc:0.9872\n",
      "Train acc:0.9907166666666667\n",
      "epoch: 9  train over\n",
      "Test acc:0.9894\n",
      "Train acc:0.9918333333333333\n",
      "epoch: 10  train over\n",
      "Test acc:0.9889\n",
      "Train acc:0.9918833333333333\n",
      "epoch: 11  train over\n",
      "Test acc:0.9881\n",
      "Train acc:0.9911333333333333\n",
      "epoch: 12  train over\n",
      "Test acc:0.989\n",
      "Train acc:0.9919333333333333\n",
      "epoch: 13  train over\n",
      "Test acc:0.9918\n",
      "Train acc:0.9933333333333333\n",
      "epoch: 14  train over\n",
      "Test acc:0.9904\n",
      "Train acc:0.9936\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[77], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m20\u001B[39m):\n\u001B[1;32m----> 3\u001B[0m     \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch:\u001B[39m\u001B[38;5;124m'\u001B[39m, epoch,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m train over\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      6\u001B[0m     test()\n",
      "Cell \u001B[1;32mIn[76], line 4\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m():\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# 训练状态\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m----> 4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i,data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m      5\u001B[0m         \u001B[38;5;66;03m# 获得一个批次的数据和标签\u001B[39;00m\n\u001B[0;32m      6\u001B[0m         inputs, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m      7\u001B[0m         inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310torch24cuda124\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    628\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 630\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310torch24cuda124\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1327\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1324\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1327\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1328\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1330\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310torch24cuda124\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1283\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1281\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m   1282\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_thread\u001B[38;5;241m.\u001B[39mis_alive():\n\u001B[1;32m-> 1283\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1284\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1285\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310torch24cuda124\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1131\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1118\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[0;32m   1119\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1128\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[0;32m   1129\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1131\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[0;32m   1133\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1134\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310torch24cuda124\\lib\\queue.py:180\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    178\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m remaining \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m:\n\u001B[0;32m    179\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m--> 180\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnot_empty\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mremaining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    181\u001B[0m item \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get()\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnot_full\u001B[38;5;241m.\u001B[39mnotify()\n",
      "File \u001B[1;32m~\\.conda\\envs\\py310torch24cuda124\\lib\\threading.py:324\u001B[0m, in \u001B[0;36mCondition.wait\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    323\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 324\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    325\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    326\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-06T12:21:13.349728800Z",
     "start_time": "2024-10-06T07:34:17.252446Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "771ce60dddc2b05",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
